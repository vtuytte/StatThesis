{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9iblg1n7C6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as k\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import Isomap\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from scipy.spatial.distance import cdist\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mnfr54p7Sbg"
      },
      "outputs": [],
      "source": [
        "matrix = pd.read_csv('data_Ngr_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "af-4-bnl7XW4",
        "outputId": "9d50e629-2ba6-45de-c4cd-818b6f149d47"
      },
      "outputs": [],
      "source": [
        "matrix.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CKvu_A372PH"
      },
      "outputs": [],
      "source": [
        "freq_table = pd.crosstab(matrix['fileID'], matrix['nN_GRM'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freq_table.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUZpywMaVslX"
      },
      "outputs": [],
      "source": [
        "file_lang = matrix.drop(['Unnamed: 0', 'nN_GRM', 'lang5'], axis=1)\n",
        "file_lang = file_lang.drop_duplicates()\n",
        "file_lang_dict = dict(zip(file_lang.fileID, file_lang.lang4))\n",
        "\n",
        "def genWeightsMFA(train, file_lang_dict, k1=5, k2=5):\n",
        "    n = train.shape[0]\n",
        "    weight_matrix = np.zeros((n, n), dtype=np.float32)\n",
        "\n",
        "    # Get group labels\n",
        "    group_list = np.asarray([file_lang_dict[file] for file in train.index])\n",
        "\n",
        "    # Compute Manhattan distances\n",
        "    distances = cdist(train.values, train.values, metric='cityblock')\n",
        "\n",
        "    for i in range(n):\n",
        "        same_group_mask = group_list == group_list[i]\n",
        "        diff_group_mask = ~same_group_mask\n",
        "\n",
        "        # Exclude self\n",
        "        same_group_mask[i] = False\n",
        "        diff_group_mask[i] = False\n",
        "\n",
        "        # Indices of same-group and diff-group\n",
        "        same_group_indices = np.where(same_group_mask)[0]\n",
        "        diff_group_indices = np.where(diff_group_mask)[0]\n",
        "\n",
        "        # Get top-k1 same group neighbors\n",
        "        if len(same_group_indices) > 0:\n",
        "            same_dists = distances[i, same_group_indices]\n",
        "            top_k1 = same_group_indices[np.argsort(same_dists)[:min(k1, len(same_group_indices))]]\n",
        "            weight_matrix[i, top_k1] = 1\n",
        "\n",
        "        # Get top-k2 diff group neighbors\n",
        "        if len(diff_group_indices) > 0:\n",
        "            diff_dists = distances[i, diff_group_indices]\n",
        "            top_k2 = diff_group_indices[np.argsort(diff_dists)[:min(k2, len(diff_group_indices))]]\n",
        "            weight_matrix[i, top_k2] = -1\n",
        "\n",
        "    return tf.constant(weight_matrix, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFr5UeVvPQcQ"
      },
      "outputs": [],
      "source": [
        "train, val = train_test_split(freq_table, test_size=0.15, stratify=np.asarray(freq_table.index.map(file_lang_dict)))\n",
        "train_numbered = train.copy()\n",
        "val_numbered = val.copy()\n",
        "train_numbered['index'] = range(0, len(train))\n",
        "val_numbered['index'] = range(0, len(val))\n",
        "\n",
        "def gen_MFA_loss(data, file_lang_dict, k1=5, k2=5):\n",
        "  weight_matrix = genWeightsMFA(data, file_lang_dict, k1, k2)\n",
        "  N = data.shape[0]\n",
        "\n",
        "  @tf.function\n",
        "  def general_MFA_loss(y_true, y_pred):\n",
        "    # Calculate\n",
        "    true = tf.reshape(tf.tile(y_true[:,:-1], [N, 1]), [N, N, -1]) # N x N x F\n",
        "    pred = tf.reshape(tf.repeat(y_pred, N, axis=0),  [N, N, -1]) # N x N x F\n",
        "    mse = tf.reduce_mean((true - pred) ** 2, axis=-1) # N x N x F\n",
        "    loss = tf.reduce_sum(tf.math.multiply(mse, weight_matrix)) / tf.cast(N, dtype=tf.float32)\n",
        "    return loss\n",
        "  return general_MFA_loss\n",
        "\n",
        "dropout_rate = 0.25\n",
        "\n",
        "class ValidationMSECallback(Callback):\n",
        "  def __init__(self, val_data):\n",
        "    super().__init__()\n",
        "    self.val_data = val_data\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    preds = self.model.predict(self.val_data, verbose=0)\n",
        "    y_true = tf.gather(self.val_data, indices=tf.range(tf.shape(self.val_data)[1] - 1), axis=1)\n",
        "    mse = mean_squared_error(y_true, preds)\n",
        "    logs = logs or {}\n",
        "    logs[\"val_mse\"] = mse\n",
        "\n",
        "class ValidationMFACallback(Callback):\n",
        "  def __init__(self, val_data, val_data_numbered, file_lang_dict, k1 = 5, k2 = 5):\n",
        "    super().__init__()\n",
        "    self.val_data = val_data\n",
        "    self.val_data_numbered = tf.cast(val_data_numbered, tf.float32)\n",
        "    self.loss_fn = gen_MFA_loss(val_data, file_lang_dict, k1, k2)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    preds = self.model.predict(self.val_data_numbered, verbose=0)\n",
        "    loss = self.loss_fn(self.val_data_numbered, preds)\n",
        "    logs = logs or {}\n",
        "    logs[\"val_loss\"] = loss\n",
        "\n",
        "class Encoder(k.Model):\n",
        "  def __init__(self, advanced = False):\n",
        "    super().__init__()\n",
        "    self.advanced = advanced\n",
        "    if self.advanced:\n",
        "      self.dropout1 = Dropout(dropout_rate)\n",
        "      self.dense1 = Dense(32, activation='relu')\n",
        "      self.dropout2 = Dropout(dropout_rate)\n",
        "      self.dense2 = Dense(8, activation='relu')\n",
        "      self.dropout3 = Dropout(dropout_rate)\n",
        "    self.dense3 = Dense(2, activation='tanh')\n",
        "\n",
        "  def call(self, x):\n",
        "    if self.advanced:\n",
        "      x = self.dropout1(x)\n",
        "      x = self.dense1(x)\n",
        "      x = self.dropout2(x)\n",
        "      x = self.dense2(x)\n",
        "      x = self.dropout3(x)\n",
        "    x = self.dense3(x)\n",
        "    return x\n",
        "\n",
        "class Decoder(k.Model):\n",
        "  def __init__(self, x, advanced = False):\n",
        "    super().__init__()\n",
        "    self.advanced = advanced\n",
        "    if self.advanced:\n",
        "      self.dense1 = Dense(8, activation='relu')\n",
        "      self.dropout1 = Dropout(dropout_rate)\n",
        "      self.dense2 = Dense(32, activation='relu')\n",
        "      self.dropout2 = Dropout(dropout_rate)\n",
        "    self.dense3 = Dense(x, activation='relu')\n",
        "\n",
        "  def call(self, x):\n",
        "    if self.advanced:\n",
        "      x = self.dense1(x)\n",
        "      x = self.dropout1(x)\n",
        "      x = self.dense2(x)\n",
        "      x = self.dropout2(x)\n",
        "    x = self.dense3(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Autoencoder_normal(k.Model):\n",
        "  def __init__(self, advanced = False):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(advanced)\n",
        "    self.decoder = Decoder(train.shape[1], advanced)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    return x\n",
        "\n",
        "class Autoencoder(k.Model):\n",
        "  def __init__(self, advanced = False):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(advanced)\n",
        "    self.decoder = Decoder(train.shape[1], advanced)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.encoder(x[:,:-1])\n",
        "    x = self.decoder(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "collapsed": true,
        "id": "Uor99toRngG8",
        "outputId": "f3779ab0-a790-4750-9bcd-d2a84403689f"
      },
      "outputs": [],
      "source": [
        "batch_size = len(train)\n",
        "epochs = 200\n",
        "\n",
        "autoencoder_normal = Autoencoder_normal()\n",
        "autoencoder_normal.compile(loss='MSE', optimizer=\"adam\")\n",
        "autoencoder_normal.summary()\n",
        "\n",
        "SAE_cp_cb = k.callbacks.ModelCheckpoint(\n",
        "    filepath=\"SAE.weights.h5\",\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_weights_only = True,\n",
        "    save_best_only=True)\n",
        "\n",
        "SAE_hist = autoencoder_normal.fit(train, train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(val, val), callbacks=[SAE_cp_cb])\n",
        "autoencoder_normal.load_weights(\"SAE.weights.h5\")\n",
        "\n",
        "encodings = pd.DataFrame(autoencoder_normal.encoder(freq_table))\n",
        "encodings['fileID'] = freq_table.index\n",
        "encodings.to_csv('encodings_AE_simple.csv')\n",
        "plt.scatter(encodings[0], encodings[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "collapsed": true,
        "id": "w3anKXSXAjAT",
        "outputId": "ded17f19-9bb4-484c-841b-04298b34cc0d"
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder()\n",
        "autoencoder.compile(loss=gen_MFA_loss(train, file_lang_dict), optimizer=\"adam\")\n",
        "autoencoder.summary()\n",
        "\n",
        "val_mse_cb = ValidationMSECallback(val_numbered)\n",
        "val_loss_cb = ValidationMFACallback(val, val_numbered, file_lang_dict)\n",
        "val_cb = [val_mse_cb, val_loss_cb]\n",
        "\n",
        "SGAE_cp_cb = k.callbacks.ModelCheckpoint(\n",
        "    filepath=\"SGAE.weights.h5\",\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_weights_only = True,\n",
        "    save_best_only=True)\n",
        "\n",
        "SGAE_hist = autoencoder.fit(train_numbered, train_numbered, batch_size=batch_size, epochs=epochs, verbose=0, callbacks=[val_cb, SGAE_cp_cb])\n",
        "autoencoder.load_weights(\"SGAE.weights.h5\")\n",
        "\n",
        "encodings = pd.DataFrame(autoencoder.encoder(freq_table))\n",
        "encodings['fileID'] = freq_table.index\n",
        "encodings.to_csv('encodings_MFA_simple.csv')\n",
        "plt.scatter(encodings[0], encodings[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A95ZVdMtCijW"
      },
      "outputs": [],
      "source": [
        "autoencoder_normal = Autoencoder_normal(advanced=True)\n",
        "autoencoder_normal.compile(loss='MSE', optimizer=\"adam\")\n",
        "autoencoder_normal.summary()\n",
        "\n",
        "AAE_cp_cb = k.callbacks.ModelCheckpoint(\n",
        "    filepath=\"AAE.weights.h5\",\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_weights_only = True,\n",
        "    save_best_only=True)\n",
        "\n",
        "AAE_hist = autoencoder_normal.fit(train, train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(val, val), callbacks=[AAE_cp_cb])\n",
        "autoencoder_normal.load_weights(\"AAE.weights.h5\")\n",
        "\n",
        "encodings = pd.DataFrame(autoencoder_normal.encoder(freq_table))\n",
        "encodings['fileID'] = freq_table.index\n",
        "encodings.to_csv('encodings_AE_advanced.csv')\n",
        "plt.scatter(encodings[0], encodings[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FeXUWEOrm-Ei"
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder(True)\n",
        "autoencoder.compile(loss=gen_MFA_loss(train, file_lang_dict,k1=5, k2=5), optimizer=\"adam\")\n",
        "autoencoder.summary()\n",
        "\n",
        "AGAE_cp_cb = k.callbacks.ModelCheckpoint(\n",
        "    filepath=\"AGAE.weights.h5\",\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_weights_only = True,\n",
        "    save_best_only=True)\n",
        "AGAE_hist = autoencoder.fit(train_numbered, train_numbered, batch_size=batch_size, epochs=epochs, verbose=0, callbacks=[val_cb, AGAE_cp_cb])\n",
        "autoencoder.load_weights(\"AGAE.weights.h5\")\n",
        "\n",
        "encodings = pd.DataFrame(autoencoder.encoder(freq_table))\n",
        "encodings['fileID'] = freq_table.index\n",
        "encodings.to_csv('encodings_MFA_advanced.csv')\n",
        "plt.scatter(encodings[0], encodings[1])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
